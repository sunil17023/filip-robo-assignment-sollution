{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException,ElementNotInteractableException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Top 30 most viewed youtube videos from wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "#scraping names of the video\n",
    "name=[]\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\")\n",
    "    for i in names:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    name.append('No details available')\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    name.append('No details available')\n",
    "print(len(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "#scraping rank of the video\n",
    "rank=[]\n",
    "try:\n",
    "    ranks=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\")\n",
    "    for i in ranks:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    rank.append('No details available')\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    rank.append('No details available')\n",
    "print(len(rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "#scraping artist/uploader of the video\n",
    "artist=[]\n",
    "try:\n",
    "    artists=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\")\n",
    "    for i in artists:\n",
    "        artist.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    artist.append('No details available')\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    artist.append('No details available')\n",
    "print(len(artist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "#scraping views of the video\n",
    "views=[]\n",
    "try:\n",
    "    views_list=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
    "    for i in views_list:\n",
    "        views.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    views.append('No details available')\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    views.append('No details available')\n",
    "print(len(views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "#scraping views of the video\n",
    "upload_date=[]\n",
    "try:\n",
    "    upload_date_list=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n",
    "    for i in upload_date_list:\n",
    "        upload_date.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    upload_date.append('No details available')\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    upload_date.append('No details available')\n",
    "print(len(upload_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                                             Name  \\\n",
      "0    1.                           \"Baby Shark Dance\"[28]   \n",
      "1    2.                                  \"Despacito\"[30]   \n",
      "2    3.                               \"Shape of You\"[31]   \n",
      "3    4.                              \"See You Again\"[32]   \n",
      "4    5.   \"Masha and the Bear – Recipe for Disaster\"[35]   \n",
      "5    6.                       \"Johny Johny Yes Papa\"[36]   \n",
      "6    7.                                \"Uptown Funk\"[37]   \n",
      "7    8.                              \"Gangnam Style\"[38]   \n",
      "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[40]   \n",
      "9   10.                                      \"Sorry\"[41]   \n",
      "10  11.                                      \"Sugar\"[42]   \n",
      "11  12.                                  \"Bath Song\"[43]   \n",
      "12  13.                \"Phonics Song with Two Words\"[44]   \n",
      "13  14.                                       \"Roar\"[45]   \n",
      "14  15.                          \"Thinking Out Loud\"[46]   \n",
      "15  16.                             \"Counting Stars\"[47]   \n",
      "16  17.                               \"Shake It Off\"[48]   \n",
      "17  18.                                   \"Bailando\"[49]   \n",
      "18  19.                                    \"Lean On\"[50]   \n",
      "19  20.                                 \"Dark Horse\"[51]   \n",
      "20  21.                                      \"Faded\"[52]   \n",
      "21  22.                             \"Dame Tu Cosita\"[53]   \n",
      "22  23.                             \"Girls Like You\"[54]   \n",
      "23  24.                                 \"Let Her Go\"[55]   \n",
      "24  25.                                   \"Mi Gente\"[56]   \n",
      "25  26.                                      \"Hello\"[57]   \n",
      "26  27.                                \"Blank Space\"[58]   \n",
      "27  28.           \"Waka Waka (This Time for Africa)\"[59]   \n",
      "28  29.                                    \"Perfect\"[60]   \n",
      "29  30.                                   \"Chantaje\"[61]   \n",
      "\n",
      "                                      Uploader/artist     Date of upload  \\\n",
      "0                      Pinkfong Kids' Songs & Stories      June 17, 2016   \n",
      "1                   Luis Fonsi featuring Daddy Yankee   January 12, 2017   \n",
      "2                                          Ed Sheeran   January 30, 2017   \n",
      "3                  Wiz Khalifa featuring Charlie Puth      April 6, 2015   \n",
      "4                                          Get Movies   January 31, 2012   \n",
      "5                                         LooLoo Kids    October 8, 2016   \n",
      "6                    Mark Ronson featuring Bruno Mars  November 19, 2014   \n",
      "7                                                 Psy      July 15, 2012   \n",
      "8                                         Miroshka TV  February 27, 2018   \n",
      "9                                       Justin Bieber   October 22, 2015   \n",
      "10                                           Maroon 5   January 14, 2015   \n",
      "11                         Cocomelon – Nursery Rhymes        May 2, 2018   \n",
      "12                                          ChuChu TV      March 6, 2014   \n",
      "13                                         Katy Perry  September 5, 2013   \n",
      "14                                         Ed Sheeran    October 7, 2014   \n",
      "15                                        OneRepublic       May 31, 2013   \n",
      "16                                       Taylor Swift    August 18, 2014   \n",
      "17  Enrique Iglesias featuring Descemer Bueno and ...     April 11, 2014   \n",
      "18              Major Lazer and DJ Snake featuring MØ     March 22, 2015   \n",
      "19                       Katy Perry featuring Juicy J  February 20, 2014   \n",
      "20                                        Alan Walker   December 3, 2015   \n",
      "21                    El Chombo featuring Cutty Ranks      April 5, 2018   \n",
      "22                         Maroon 5 featuring Cardi B       May 31, 2018   \n",
      "23                                          Passenger      July 25, 2012   \n",
      "24                         J Balvin and Willy William      June 29, 2017   \n",
      "25                                              Adele   October 22, 2015   \n",
      "26                                       Taylor Swift  November 10, 2014   \n",
      "27                    Shakira featuring Freshlyground       June 4, 2010   \n",
      "28                                         Ed Sheeran   November 9, 2017   \n",
      "29                           Shakira featuring Maluma  November 18, 2016   \n",
      "\n",
      "   Views(in billion)  \n",
      "0               7.20  \n",
      "1               7.06  \n",
      "2               5.07  \n",
      "3               4.82  \n",
      "4               4.37  \n",
      "5               4.24  \n",
      "6               4.01  \n",
      "7               3.86  \n",
      "8               3.65  \n",
      "9               3.36  \n",
      "10              3.32  \n",
      "11              3.25  \n",
      "12              3.24  \n",
      "13              3.21  \n",
      "14              3.12  \n",
      "15              3.11  \n",
      "16              2.98  \n",
      "17              2.93  \n",
      "18              2.92  \n",
      "19              2.91  \n",
      "20              2.90  \n",
      "21              2.89  \n",
      "22              2.88  \n",
      "23              2.83  \n",
      "24              2.81  \n",
      "25              2.74  \n",
      "26              2.67  \n",
      "27              2.64  \n",
      "28              2.62  \n",
      "29              2.60  \n"
     ]
    }
   ],
   "source": [
    "#preparing dataframe\n",
    "df=pd.DataFrame({\"Rank\":rank,\n",
    "                 \"Name\":name,\n",
    "                \"Uploader/artist\":artist,\n",
    "                \"Date of upload\":upload_date,\n",
    "                \"Views(in billion)\":views})\n",
    "\n",
    "df.to_csv(\"top_30_videos\",index=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Team India's international fixtures from bcci.tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.bcci.tv/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#going to international fixtures page\n",
    "fixtures=driver.find_element_by_xpath(\"//div[@class='navigation__drop-down drop-down drop-down--reveal-on-hover']/div/ul/li/a\")\n",
    "try:\n",
    "    fixtures.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(fixtures.get_attribute('href'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "match_page=driver.find_elements_by_xpath(\"//div[@class='js-list']/a\")\n",
    "for i in match_page:\n",
    "    urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "match=[]\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "time=[]\n",
    "for i in urls:#list of urls of match description pages\n",
    "    driver.get(i)\n",
    "    try:#scarping match title\n",
    "        match_title=driver.find_element_by_xpath(\"//p[@class='mc-header-info__match-description']/span\")\n",
    "        match.append(match_title.text)\n",
    "    except NoSuchElementException:#handling no such element exception\n",
    "        match.append('No details available')\n",
    "    try:#scarping series title\n",
    "        series_title=driver.find_element_by_xpath(\"//h1[@class='mc-header-info__title']/strong\")\n",
    "        series.append(series_title.text)\n",
    "    except NoSuchElementException:#handling no such element exception\n",
    "        series.append(\"No details Available\")\n",
    "    try:#scarping match venue\n",
    "        place_title=driver.find_element_by_xpath(\"//h1[@class='mc-header-info__title']\")\n",
    "        place.append(place_title.text.split()[-1])\n",
    "    except NoSuchElementException:#handling no such element exception\n",
    "        place.append(\"No details Available\")\n",
    "    try:#scarping date of match \n",
    "        date_title=driver.find_element_by_xpath(\"//div[@class='mc-header-scorebox__datetime']/strong\")\n",
    "        date.append(date_title.text)\n",
    "    except NoSuchElementException:#handling no such element exception\n",
    "        date.append(\"No details Available\")        \n",
    "    try:#scarping time of the match\n",
    "        time_title=driver.find_element_by_xpath(\"//div[@class='mc-header-scorebox__datetime']/span\")\n",
    "        time.append(time_title.text)\n",
    "    except NoSuchElementException:#handling no such element exception\n",
    "        time.append(\"No details Available\")     \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Match             Series       Place                  Date       Time\n",
      "0    1ST ODI  Australia v India      Sydney    Friday 27 November  09:10 IST\n",
      "1    2ND ODI  Australia v India      Sydney    Sunday 29 November  09:10 IST\n",
      "2    3RD ODI  Australia v India    Canberra  Wednesday 2 December  09:10 IST\n",
      "3   1ST T20I  Australia v India    Canberra     Friday 4 December  13:40 IST\n",
      "4   2ND T20I  Australia v India      Sydney     Sunday 6 December  13:40 IST\n",
      "5   3RD T20I  Australia v India      Sydney    Tuesday 8 December  13:40 IST\n",
      "6   1ST TEST  Australia v India    Adelaide  Thursday 17 December  09:30 IST\n",
      "7   2ND TEST  Australia v India   Melbourne  Saturday 26 December  05:00 IST\n",
      "8   3RD TEST  Australia v India      Sydney    Thursday 7 January  05:00 IST\n",
      "9   4TH TEST  Australia v India    Brisbane     Friday 15 January  05:30 IST\n",
      "10  1ST TEST    England v India  Nottingham    Wednesday 4 August  15:30 IST\n",
      "11  2ND TEST    England v India      London    Thursday 12 August  15:30 IST\n",
      "12  3RD TEST    England v India       Leeds   Wednesday 25 August  15:30 IST\n",
      "13  4TH TEST    England v India      London  Thursday 2 September  15:30 IST\n",
      "14  5TH TEST    England v India  Manchester   Friday 10 September  15:30 IST\n"
     ]
    }
   ],
   "source": [
    "#preparing the dataframe\n",
    "df=pd.DataFrame({\"Match\":match,\n",
    "                \"Series\":series,\n",
    "                \"Place\":place,\n",
    "                \"Date\":date,\n",
    "                \"Time\":time})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.The list of all selenium exceptions and their description from Guru99.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.guru99.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on selenium option under testing menu open its tutorial\n",
    "selenium_link=driver.find_element_by_xpath(\"//li[@class='g-menu-item g-menu-item-type-component g-menu-item-121  ']/a\")\n",
    "try:\n",
    "    selenium_link.click()\n",
    "except ElementNotInteractableException:#handling element not clickable exception\n",
    "    driver.get(selenium_link.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "exception_handle_link=driver.find_element_by_xpath(\"//a[@title='Selenium Exception Handling (Common Exceptions List)']\")\n",
    "try:\n",
    "    exception_handle_link.click()\n",
    "except ElementNotInteractableException:#handling element not clickable exception\n",
    "    driver.get(exception_handle_link.get_attribute('href'))                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "#scraping exceptions names\n",
    "name=[]\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[1]\")\n",
    "    for i in names[1:]:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    name.append('No details available')\n",
    "print(len(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "#scraping exceptions description\n",
    "desc=[]\n",
    "try:\n",
    "    desc_list=driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[2]\")\n",
    "    for i in desc_list[1:]:\n",
    "        desc.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    desc.append('No details available')\n",
    "print(len(desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Exception_name  \\\n",
      "0            ElementNotVisibleException   \n",
      "1         ElementNotSelectableException   \n",
      "2                NoSuchElementException   \n",
      "3                  NoSuchFrameException   \n",
      "4               NoAlertPresentException   \n",
      "5                 NoSuchWindowException   \n",
      "6        StaleElementReferenceException   \n",
      "7              SessionNotFoundException   \n",
      "8                      TimeoutException   \n",
      "9                    WebDriverException   \n",
      "10            ConnectionClosedException   \n",
      "11     ElementClickInterceptedException   \n",
      "12      ElementNotInteractableException   \n",
      "13             ErrorInResponseException   \n",
      "14  ErrorHandler.UnknownServerException   \n",
      "15         ImeActivationFailedException   \n",
      "16             ImeNotAvailableException   \n",
      "17         InsecureCertificateException   \n",
      "18             InvalidArgumentException   \n",
      "19         InvalidCookieDomainException   \n",
      "20          InvalidCoordinatesException   \n",
      "21          InvalidElementStateExceptio   \n",
      "22            InvalidSessionIdException   \n",
      "23       InvalidSwitchToTargetException   \n",
      "24                  JavascriptException   \n",
      "25                        JsonException   \n",
      "26             NoSuchAttributeException   \n",
      "27       MoveTargetOutOfBoundsException   \n",
      "28               NoSuchContextException   \n",
      "29                NoSuchCookieException   \n",
      "30                    NotFoundException   \n",
      "31          RemoteDriverServerException   \n",
      "32                  ScreenshotException   \n",
      "33           SessionNotCreatedException   \n",
      "34           UnableToSetCookieException   \n",
      "35           UnexpectedTagNameException   \n",
      "36              UnhandledAlertException   \n",
      "37      UnexpectedAlertPresentException   \n",
      "38               UnknownMethodException   \n",
      "39          UnreachableBrowserException   \n",
      "40          UnsupportedCommandException   \n",
      "\n",
      "                                          Description  \n",
      "0   This type of Selenium exception occurs when an...  \n",
      "1   This Selenium exception occurs when an element...  \n",
      "2   This Exception occurs if an element could not ...  \n",
      "3   This Exception occurs if the frame target to b...  \n",
      "4   This Exception occurs when you switch to no pr...  \n",
      "5   This Exception occurs if the window target to ...  \n",
      "6   This Selenium exception occurs happens when th...  \n",
      "7   The WebDriver is acting after you quit the bro...  \n",
      "8   Thrown when there is not enough time for a com...  \n",
      "9   This Exception takes place when the WebDriver ...  \n",
      "10  This type of Exception takes place when there ...  \n",
      "11  The command may not be completed as the elemen...  \n",
      "12  This Selenium exception is thrown when any ele...  \n",
      "13  This happens while interacting with the Firefo...  \n",
      "14  Exception is used as a placeholder in case if ...  \n",
      "15  This expectation will occur when IME engine ac...  \n",
      "16    It takes place when IME support is unavailable.  \n",
      "17  Navigation made the user agent to hit a certif...  \n",
      "18  It occurs when an argument does not belong to ...  \n",
      "19  This happens when you try to add a cookie unde...  \n",
      "20  This type of Exception matches an interacting ...  \n",
      "21  It occurs when command can't be finished when ...  \n",
      "22  This Exception took place when the given sessi...  \n",
      "23  This occurs when the frame or window target to...  \n",
      "24  This issue occurs while executing JavaScript g...  \n",
      "25  It occurs when you afford to get the session w...  \n",
      "26  This kind of Exception occurs when the attribu...  \n",
      "27  It takes place if the target provided to the A...  \n",
      "28           ContextAware does mobile device testing.  \n",
      "29  This Exception occurs when no cookie matching ...  \n",
      "30  This Exception is a subclass of WebDriverExcep...  \n",
      "31  This Selenium exception is thrown when the ser...  \n",
      "32            It is not possible to capture a screen.  \n",
      "33  It happens when a new session could not be suc...  \n",
      "34  This occurs if a driver is unable to set a coo...  \n",
      "35  Happens if a support class did not get a web e...  \n",
      "36  This expectation occurs when there is an alert...  \n",
      "37  It occurs when there is the appearance of an u...  \n",
      "38  This Exception happens when the requested comm...  \n",
      "39  This Exception occurs only when the browser is...  \n",
      "40  This occurs when remote WebDriver does n't sen...  \n"
     ]
    }
   ],
   "source": [
    "#creating dataframe\n",
    "df=pd.DataFrame({\"Exception_name\":name,\n",
    "                \"Description\":desc})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.State-wise GDP of india from StatisticTimes.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#economy button\n",
    "economy=driver.find_element_by_xpath(\"//div[@class='dropdown'][2]/div/a[2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    economy.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(economy.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching gdp of india state link\n",
    "GDP=driver.find_element_by_xpath(\"//ul[@style='list-style-type:none;margin-left:20px;']/li/a\")\n",
    "try:\n",
    "    GDP.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(GDP.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "#scraping rank\n",
    "rank=[]\n",
    "try:\n",
    "    ranks=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[1]\")\n",
    "    for i in ranks:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    rank.append('No details available')\n",
    "print(len(rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "#scraping States\n",
    "State=[]\n",
    "try:\n",
    "    states=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[2]\")\n",
    "    for i in states:\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    State.append('No details available')\n",
    "print(len(State))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "#scraping GSDP(18-19)\n",
    "GSDP_18=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[3]\")\n",
    "    for i in info:\n",
    "        GSDP_18.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    GSDP_18.append('No details available')\n",
    "print(len(GSDP_18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "#scraping GSDP(17-18)\n",
    "GSDP_17=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[4]\")\n",
    "    for i in info:\n",
    "        GSDP_17.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    GSDP_17.append('No details available')\n",
    "print(len(GSDP_17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "#scraping share 2017\n",
    "share=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[5]\")\n",
    "    for i in info:\n",
    "        share.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    share.append('No details available')\n",
    "print(len(share))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "#scraping GDP(billion$)\n",
    "GDP_billion=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[6]\")\n",
    "    for i in info:\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    GDP_billion.append('No details available')\n",
    "print(len(GDP_billion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                      State GSDP(18-19) GSDP(17-18) Share_2017  \\\n",
      "0     1                Maharashtra           -   2,411,600     14.11%   \n",
      "1     2                 Tamil Nadu   1,664,159   1,461,841      8.55%   \n",
      "2     3              Uttar Pradesh   1,542,432   1,376,324      8.05%   \n",
      "3     4                  Karnataka   1,535,224   1,350,257      7.90%   \n",
      "4     5                    Gujarat           -   1,314,680      7.69%   \n",
      "5     6                West Bengal   1,177,586     999,585      5.85%   \n",
      "6     7                  Rajasthan     929,124     835,558      4.89%   \n",
      "7     8             Andhra Pradesh     933,402     809,547      4.74%   \n",
      "8     9                  Telangana     865,688     753,811      4.41%   \n",
      "9    10             Madhya Pradesh     809,327     728,242      4.26%   \n",
      "10   11                     Kerala           -     700,532      4.10%   \n",
      "11   12                      Delhi     779,652     690,098      4.04%   \n",
      "12   13                    Haryana     707,126     626,054      3.66%   \n",
      "13   14                      Bihar     557,490     484,740      2.84%   \n",
      "14   15                     Punjab     521,861     479,141      2.80%   \n",
      "15   16                     Odisha     485,376     436,374      2.55%   \n",
      "16   17                      Assam           -     288,494      1.69%   \n",
      "17   18               Chhattisgarh     311,660     284,194      1.66%   \n",
      "18   19                  Jharkhand     307,581     276,243      1.62%   \n",
      "19   20                Uttarakhand     245,895     222,836      1.30%   \n",
      "20   21           Himachal Pradesh     153,181     140,613      0.82%   \n",
      "21   22            Jammu & Kashmir           -     138,488      0.81%   \n",
      "22   23                        Goa      77,172      70,493      0.41%   \n",
      "23   24                    Tripura           -      46,133      0.27%   \n",
      "24   25                 Chandigarh           -      38,806      0.23%   \n",
      "25   26                 Puducherry      36,656      32,962      0.19%   \n",
      "26   27                  Meghalaya           -      30,790      0.18%   \n",
      "27   28                   Nagaland           -      24,281      0.14%   \n",
      "28   29                    Manipur           -      23,968      0.14%   \n",
      "29   30                     Sikkim      26,786      23,495      0.14%   \n",
      "30   31          Arunachal Pradesh           -      22,045      0.13%   \n",
      "31   32                    Mizoram           -      19,457      0.11%   \n",
      "32   33  Andaman & Nicobar Islands           -       7,871      0.05%   \n",
      "\n",
      "   GDP(Billion_$)  \n",
      "0         374.196  \n",
      "1         226.827  \n",
      "2         213.558  \n",
      "3         209.513  \n",
      "4         203.993  \n",
      "5         155.101  \n",
      "6         129.650  \n",
      "7         125.614  \n",
      "8         116.965  \n",
      "9         112.998  \n",
      "10        108.698  \n",
      "11        107.079  \n",
      "12         97.142  \n",
      "13         75.215  \n",
      "14         74.346  \n",
      "15         67.710  \n",
      "16         44.764  \n",
      "17         44.097  \n",
      "18         42.863  \n",
      "19         34.576  \n",
      "20         21.818  \n",
      "21         21.489  \n",
      "22         10.938  \n",
      "23          7.158  \n",
      "24          6.021  \n",
      "25          5.115  \n",
      "26          4.778  \n",
      "27          3.768  \n",
      "28          3.719  \n",
      "29          3.646  \n",
      "30          3.421  \n",
      "31          3.019  \n",
      "32          1.221  \n"
     ]
    }
   ],
   "source": [
    "#creatng dataframe\n",
    "df=pd.DataFrame({'Rank':rank,\n",
    "                'State':State,\n",
    "                'GSDP(18-19)':GSDP_18,\n",
    "                'GSDP(17-18)':GSDP_17,\n",
    "                'Share_2017':share,\n",
    "                'GDP(Billion_$)':GDP_billion})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Trending repositories from github.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding explore-trending option\n",
    "explore=driver.find_element_by_xpath(\"//ul[@class='list-style-none mb-3']/li[3]/a\")\n",
    "driver.get(explore.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "#scraping repositories title\n",
    "repo_title=[]\n",
    "try:\n",
    "    repos=driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']\")\n",
    "    for i in repos:\n",
    "        repo_title.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    repo_title.append('No details available')\n",
    "print(len(repo_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "#scraping repositories description\n",
    "repo_desc=[]\n",
    "try:\n",
    "    descriptions=driver.find_elements_by_xpath(\"//p[@class='col-9 text-gray my-1 pr-4']\")\n",
    "    for i in descriptions:\n",
    "        repo_desc.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    repo_desc.append('No details available')\n",
    "print(len(repo_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_urls=[]\n",
    "repos=driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']/a\")\n",
    "for i in repos:\n",
    "    repo_urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "Contributors_count=[]\n",
    "Language_used=[]\n",
    "for i in repo_urls:\n",
    "    driver.get(i)\n",
    "    l=[]\n",
    "    try:#scraping contributors count\n",
    "        count=driver.find_element_by_xpath(\"//h2[@class='h4 mb-3']/a[contains(text(),'Contributors')]/span\")\n",
    "        Contributors_count.append(count.text)\n",
    "    except NoSuchElementException:#handling no such element exception\n",
    "        Contributors_count.append('No details available')\n",
    "     #scraping languages used   \n",
    "    languages=driver.find_elements_by_xpath(\"//span[@class='text-gray-dark text-bold mr-1']\")\n",
    "    if languages:    \n",
    "        for i in languages:\n",
    "            l.append(i.text)\n",
    "    else:\n",
    "        l.append('No languages used')\n",
    "    Language_used.append(l)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Title  \\\n",
      "0                          tailwindlabs / tailwindcss   \n",
      "1                                       servo / servo   \n",
      "2                                       istio / istio   \n",
      "3                                   VVNoodle / PS5bot   \n",
      "4                               streamich / react-use   \n",
      "5                            apple / tensorflow_macos   \n",
      "6                                 directus / directus   \n",
      "7                                   upptime / upptime   \n",
      "8                                  oam-dev / kubevela   \n",
      "9                             ossu / computer-science   \n",
      "10                                     nuxt / nuxt.js   \n",
      "11                                     dromara / soul   \n",
      "12                                google / googletest   \n",
      "13                        Hari-Nagarajan / nvidia-bot   \n",
      "14         soulmachine / machine-learning-cheat-sheet   \n",
      "15                                cncf / sig-security   \n",
      "16                                    nlohmann / json   \n",
      "17                     y1ndan / genshin-impact-helper   \n",
      "18                 jackfrued / Python-Core-50-Courses   \n",
      "19                      devMEremenko / XcodeBenchmark   \n",
      "20                                ossu / data-science   \n",
      "21                                       3b1b / manim   \n",
      "22                            ClickHouse / ClickHouse   \n",
      "23                            chaos-mesh / chaos-mesh   \n",
      "24  walidshaari / Certified-Kubernetes-Security-Sp...   \n",
      "\n",
      "                                          Description    Contributors_count  \\\n",
      "0   A utility-first CSS framework for rapid UI dev...                   151   \n",
      "1                            The Servo Browser Engine                 1,079   \n",
      "2     Connect, secure, control, and observe services.                   646   \n",
      "3   bot to monitor PS5 stock and auto-purchase whe...  No details available   \n",
      "4                                     React Hooks — 👍                   144   \n",
      "5   TensorFlow for macOS 11.0+ accelerated using A...                     3   \n",
      "6   Open-Source Data Platform — Directus wraps you...                    17   \n",
      "7   ⬆️ Uptime monitor and status page powered by G...                    10   \n",
      "8   An Easy-to-use yet Fully Extensible App Platfo...                    23   \n",
      "9   🎓 Path to a free self-taught education in Comp...                   103   \n",
      "10                        The Intuitive Vue Framework                   283   \n",
      "11                  High-Performance Java API Gateway                    29   \n",
      "12  Googletest - Google Testing and Mocking Framework                   308   \n",
      "13                  Tool to help us buy a GPU in 2020                    39   \n",
      "14  Classical equations and diagrams in machine le...                    10   \n",
      "15  😎CNCF Special Interest Group on Security -- se...                    86   \n",
      "16                                JSON for Modern C++                   178   \n",
      "17  Auto get Genshin Impact daily bonus by GitHub ...                     3   \n",
      "18                                      Python语言基础50课  No details available   \n",
      "19  XcodeBenchmark measures the compilation time o...                    26   \n",
      "20  📊 Path to a free self-taught education in Data...                    13   \n",
      "21       Animation engine for explanatory math videos                    96   \n",
      "22   ClickHouse is a free analytics DBMS for big data                   563   \n",
      "23       A Chaos Engineering Platform for Kubernetes.                    65   \n",
      "24  Online resources that will help you prepare fo...                     6   \n",
      "\n",
      "                                        Language_used  \n",
      "0                                   [CSS, JavaScript]  \n",
      "1     [Rust, Python, WebIDL, C++, Java, Shell, Other]  \n",
      "2   [Go, Shell, Makefile, Python, Smarty, Dockerfile]  \n",
      "3                      [TypeScript, JavaScript, HTML]  \n",
      "4                            [TypeScript, JavaScript]  \n",
      "5                                             [Shell]  \n",
      "6   [Vue, TypeScript, SCSS, Shell, JavaScript, CSS...  \n",
      "7                                 [No languages used]  \n",
      "8   [Go, JavaScript, Less, HTML, Makefile, CSS, Ot...  \n",
      "9                                 [No languages used]  \n",
      "10                     [JavaScript, HTML, Vue, Other]  \n",
      "11                                      [Java, Other]  \n",
      "12  [C++, Python, CMake, C, Shell, Starlark, Makef...  \n",
      "13                                [Python, Batchfile]  \n",
      "14                                              [TeX]  \n",
      "15                                [No languages used]  \n",
      "16                                       [C++, Other]  \n",
      "17                                           [Python]  \n",
      "18                                [No languages used]  \n",
      "19                               [Swift, Shell, Ruby]  \n",
      "20                                [No languages used]  \n",
      "21                                           [Python]  \n",
      "22  [C++, Python, Shell, JavaScript, CMake, C, Other]  \n",
      "23  [Go, TypeScript, Shell, Makefile, Groovy, Pyth...  \n",
      "24                                [No languages used]  \n"
     ]
    }
   ],
   "source": [
    "#creating dataframe\n",
    "df=pd.DataFrame({'Title':repo_title,\n",
    "                'Description':repo_desc,\n",
    "                'Contributors_count':Contributors_count,\n",
    "                'Language_used':Language_used})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Top 100 songs on billiboard.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking charts button\n",
    "charts=driver.find_element_by_xpath(\"//a[@class='header__main-link header__main-link--charts']\")\n",
    "try:\n",
    "    charts.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(charts.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the hot 100 songs link\n",
    "top_100=driver.find_element_by_xpath(\"//a[@class='charts-landing__link charts-landing__video--background']\")\n",
    "try:\n",
    "    top_100.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(top_100.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#scraping song names\n",
    "song_name=[]\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "    for i in names:\n",
    "        song_name.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    song_name.append('No details available')\n",
    "print(len(song_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#scraping song names\n",
    "artist_name=[]\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__artist text--truncate color--secondary']\")\n",
    "    for i in names:\n",
    "        artist_name.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    artist_name.append('No details available')\n",
    "print(len(artist_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#scraping last week rank\n",
    "last_week_rank=[]\n",
    "try:\n",
    "    ranks=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "    for i in ranks:\n",
    "        last_week_rank.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    last_week_rank.append('No details available')\n",
    "print(len(last_week_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#scraping peak rank\n",
    "peak_rank=[]\n",
    "try:\n",
    "    ranks=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "    for i in ranks:\n",
    "        peak_rank.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    peak_rank.append('No details available')\n",
    "print(len(peak_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#scraping weeks on chart\n",
    "weeks=[]\n",
    "try:\n",
    "    week_count=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "    for i in week_count:\n",
    "        weeks.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    weeks.append('No details available')\n",
    "print(len(weeks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Song_Name                                Artist_Name  \\\n",
      "0                  Mood               24kGoldn Featuring iann dior   \n",
      "1             Positions                              Ariana Grande   \n",
      "2                I Hope       Gabby Barrett Featuring Charlie Puth   \n",
      "3   Laugh Now Cry Later                   Drake Featuring Lil Durk   \n",
      "4       Blinding Lights                                 The Weeknd   \n",
      "..                  ...                                        ...   \n",
      "95     Take You Dancing                               Jason Derulo   \n",
      "96              Whoopty                                         CJ   \n",
      "97      Just Like Magic                              Ariana Grande   \n",
      "98    F*ck You, Goodbye  The Kid LAROI Featuring Machine Gun Kelly   \n",
      "99            La Toxica                                    Farruko   \n",
      "\n",
      "   Last_week_rank Peak Weeks_on_chart  \n",
      "0               1    1             14  \n",
      "1               2    1              3  \n",
      "2               5    3             46  \n",
      "3               3    2             13  \n",
      "4               4    1             50  \n",
      "..            ...  ...            ...  \n",
      "95            100   96              2  \n",
      "96              -   97              1  \n",
      "97             43   43              2  \n",
      "98              -   99              1  \n",
      "99             99   98              3  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating dataframe\n",
    "df=pd.DataFrame({'Song_Name':song_name,\n",
    "                'Artist_Name':artist_name,\n",
    "                'Last_week_rank':last_week_rank,\n",
    "                'Peak':peak_rank,\n",
    "                'Weeks_on_chart':weeks})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Data science recruiters on Naukri.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on recruiters link\n",
    "recruiters=driver.find_element_by_xpath(\"//a[@title='Search Recruiters']\")\n",
    "driver.get(recruiters.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accesing search bar\n",
    "search=driver.find_element_by_xpath(\"//input[@class='sugInp']\")\n",
    "search.send_keys(\"Data Science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search button\n",
    "button=driver.find_element_by_xpath(\"//button[@id='qsbFormBtn']\")\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "#scrapping names\n",
    "name=[]\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//div[@class='recInfo']/div/p/a[1]\")\n",
    "    for i in names:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    name.append('No details available')\n",
    "print(len(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "#scrapping designation\n",
    "designation=[]\n",
    "try:\n",
    "    designation_list=driver.find_elements_by_xpath(\"//div[@class='recInfo']/div/p/span[1]\")\n",
    "    for i in designation_list:\n",
    "        designation.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    designation.append('No details available')\n",
    "print(len(designation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "#scrapping company names\n",
    "company=[]\n",
    "try:\n",
    "    companies=driver.find_elements_by_xpath(\"//div[@class='recInfo']/div/p/a[2]\")\n",
    "    for i in companies:\n",
    "        company.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    company.append('No details available')\n",
    "print(len(company))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "#skills they hire for\n",
    "skill=[]\n",
    "try:\n",
    "    skills=driver.find_elements_by_xpath(\"//div[@class='recInfo']/div[2]\")\n",
    "    for i in skills:\n",
    "        skill.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    skill.append('No details available')\n",
    "print(len(skill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "location=[]\n",
    "soup=BeautifulSoup(driver.page_source,'html.parser')\n",
    "l=soup.find_all('div',attrs={'vcard'})\n",
    "for i in l:\n",
    "    try:\n",
    "        location.append(i.find('small').text)\n",
    "    except AttributeError :\n",
    "        location.append(\"No details available\")\n",
    "print(len(location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Name  \\\n",
      "0                                    Aakash Harit   \n",
      "1                            shravan Kumar Gaddam   \n",
      "2                    Talent Acquisition Executive   \n",
      "3                                    Anik Agrawal   \n",
      "4                        MARSIAN Technologies LLP   \n",
      "5                                    subhas patel   \n",
      "6    Abhishek - Only Analytics Hiring - India and   \n",
      "7   Institute for Financial Management and Resear   \n",
      "8                                     Balu Ramesh   \n",
      "9                                   Asif Lucknowi   \n",
      "10                                InstaFinancials   \n",
      "11                                Kalpana Dumpala   \n",
      "12                                        Mubarak   \n",
      "13                                 Kushal Rastogi   \n",
      "14                                  Manisha Yadav   \n",
      "15                                   Kapil Devang   \n",
      "16                                    Riya Rajesh   \n",
      "17                                          Rakhi   \n",
      "18                             Mahesh Babu Channa   \n",
      "19                           Rashmi Bhattacharjee   \n",
      "20                                  Faizan Kareem   \n",
      "21                                 Rithika dadwal   \n",
      "22                                  Azahar Shaikh   \n",
      "23                                     Pooja Seth   \n",
      "24                             Sandhya Khandagale   \n",
      "25                                      Shaun Rao   \n",
      "26                                          Manas   \n",
      "27                                Srikanth Bellup   \n",
      "28                                          kumar   \n",
      "29                                   Sunil Vedula   \n",
      "30                                    Rajat Kumar   \n",
      "31                                      Jayanth N   \n",
      "32                                  Prateek Kumar   \n",
      "33                                       SREEDHAR   \n",
      "34                                    Amit Sharma   \n",
      "35                                          Kanan   \n",
      "36                           Shashikant Chaudhary   \n",
      "37                                           Brad   \n",
      "38                                   Rutuja Pawar   \n",
      "39                            Madhusudhan Sridhar   \n",
      "40                                    Ankit Sinha   \n",
      "41                                 Gaurav Chouhan   \n",
      "42                                   Rashi Kacker   \n",
      "43                                        Ashwini   \n",
      "44                                   Balaji Kolli   \n",
      "45                                 Rajani Nagaraj   \n",
      "46                                    ROHIT Kumar   \n",
      "47                                 Amir Chowdhury   \n",
      "48                                 Shailja Mishra   \n",
      "49                                   Sunny Sharma   \n",
      "\n",
      "                      Designation  \\\n",
      "0                      HR Manager   \n",
      "1               Company Recruiter   \n",
      "2        Recruitment Professional   \n",
      "3               Company Recruiter   \n",
      "4                      Company HR   \n",
      "5                     Founder CEO   \n",
      "6     Recruitment Lead Consultant   \n",
      "7               Programme Manager   \n",
      "8                HR Administrator   \n",
      "9                        Director   \n",
      "10                 Human Resource   \n",
      "11               Executive Hiring   \n",
      "12                     Company HR   \n",
      "13                     Company HR   \n",
      "14                   HR Executive   \n",
      "15                     HR Manager   \n",
      "16     Manager Talent Acquisition   \n",
      "17         Recruitment Consultant   \n",
      "18                   HR Team Lead   \n",
      "19                        HR Head   \n",
      "20                     HR MANAGER   \n",
      "21                   HR Recruiter   \n",
      "22              Company Recruiter   \n",
      "23         IT Technical Recruiter   \n",
      "24                   HR Recruiter   \n",
      "25        Manager Human Resources   \n",
      "26        Lead Talent acquisition   \n",
      "27                       Director   \n",
      "28                     Proprietor   \n",
      "29                            CEO   \n",
      "30                    Founder CEO   \n",
      "31                Project Manager   \n",
      "32                           Head   \n",
      "33         Recruitment Consultant   \n",
      "34                     Consultant   \n",
      "35   senior technology instructor   \n",
      "36       HR Recruiter/HR Excutive   \n",
      "37  Manager, Technical Recruiting   \n",
      "38            Technical Recruiter   \n",
      "39                Erp Implementer   \n",
      "40                 Head Analytics   \n",
      "41        Chief Technical Officer   \n",
      "42             Sr Product Manager   \n",
      "43       Director Global Delivery   \n",
      "44                     Co Founder   \n",
      "45                     HR Manager   \n",
      "46                      Architect   \n",
      "47               Managing Partner   \n",
      "48                     HR Manager   \n",
      "49         Managing Director - HR   \n",
      "\n",
      "                                           Company                  Location  \\\n",
      "0                             Data Science Network                     Delhi   \n",
      "1                    Shore Infotech India Pvt. Ltd  Hyderabad / Secunderabad   \n",
      "2                                       XenonStack                Chandigarh   \n",
      "3            Enerlytics Software Solutions Pvt Ltd                 Ahmedabad   \n",
      "4                         MARSIAN Technologies LLP                      Pune   \n",
      "5                                  LibraryXProject             UK - (london)   \n",
      "6       Apidel Technologies Division of Transpower         Vadodara / Baroda   \n",
      "7                                             IFMR                   Chennai   \n",
      "8                      Techvantage Systems Pvt Ltd                Trivandrum   \n",
      "9                       Weupskill- Live Wire India                    Indore   \n",
      "10                CBL Data Science Private Limited     Bengaluru / Bangalore   \n",
      "11                              Innominds Software  Hyderabad / Secunderabad   \n",
      "12                                        MoneyTap     Bengaluru / Bangalore   \n",
      "13              QuantMagnum Technologies Pvt. Ltd.                    Mumbai   \n",
      "14                                        Easi Tax               Navi Mumbai   \n",
      "15                                  BISP Solutions                    Bhopal   \n",
      "16                     Novelworx Digital Solutions                    Cochin   \n",
      "17                     Walkingtext Private Limited     Bengaluru / Bangalore   \n",
      "18                               SocialPrachar.com  Hyderabad / Secunderabad   \n",
      "19         AXESTRACK SOFTWARE SOLUTIONS PRIVATE...                     Delhi   \n",
      "20                   FirstTech Consaltants Pvt.Ltd  Hyderabad / Secunderabad   \n",
      "21                                Affine Analytics                      Pune   \n",
      "22                 NEAL ANALYTICS SERVICES PVT LTD                      Pune   \n",
      "23                                      RAPS iTech                Chandigarh   \n",
      "24                 Compumatrice Multimedia Pvt Ltd                      Pune   \n",
      "25                              Exela Technologies                      Pune   \n",
      "26      Autumn Leaf Consulting Services Private...     Bengaluru / Bangalore   \n",
      "27                        TeachR Robotics Pvt. Ltd  Hyderabad / Secunderabad   \n",
      "28                                         trainin     Bengaluru / Bangalore   \n",
      "29                            Nanoprecise Sci Corp      No details available   \n",
      "30                  R.S Consultancy &amp; Services                     Delhi   \n",
      "31        Dollarbird Information Services Pvt, Ltd           Mysoru / Mysore   \n",
      "32                                         Trisect                     Noida   \n",
      "33     JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED  Hyderabad / Secunderabad   \n",
      "34                                 ASCO consulting                 New Delhi   \n",
      "35                                         NY INST                   Chennai   \n",
      "36  3D India Staffing Research &amp; Consulting...                   Aligarh   \n",
      "37                                     O.C. Tanner            Salt Lake City   \n",
      "38                                   Demand Matrix                      Pune   \n",
      "39                             MADHUSUDHAN SRIDHAR     Bengaluru / Bangalore   \n",
      "40                                  Suntech Global                    Mumbai   \n",
      "41                        Strategic Consulting Lab                    Indore   \n",
      "42                            Impel Labs Pvt. Ltd.     Bengaluru / Bangalore   \n",
      "43                                    MRP Advisers                    MYSORE   \n",
      "44                   Saras Solutions India Pvt Ltd  Hyderabad / Secunderabad   \n",
      "45                                     WildJasmine     Bengaluru / Bangalore   \n",
      "46                             LNT Private Limited                    Mumbai   \n",
      "47                                     Granular.ai      No details available   \n",
      "48                               Certybox Pvt.Ltd.                     Noida   \n",
      "49                       Western Service Providers                    Mumbai   \n",
      "\n",
      "                                        Skills I hire  \n",
      "0   Classic ASP Developer, Internet Marketing Prof...  \n",
      "1   .Net, Java, Data Science, Linux Administration...  \n",
      "2   Web Designing, html5, Angular.js, seo, hadoop,...  \n",
      "3   Mean Stack, javascript, angularjs, mongodb, We...  \n",
      "4   Data Science, Artificial Intelligence, Machine...  \n",
      "5   Hadoop, Spark, Digital Strategy, Data Architec...  \n",
      "6   Analytics, Business Intelligence, Business Ana...  \n",
      "7                                        Data Science  \n",
      "8   Machine Learning, algorithms, Go Getter, Compu...  \n",
      "9   Technical Training, Software Development, Pres...  \n",
      "10  Software Development, It Sales, Account Manage...  \n",
      "11  Qa, Ui/ux, Java Developer, Java Architect, C++...  \n",
      "12  Business Intelligence, Data Warehousing, Data ...  \n",
      "13  Office Administration, Hr Administration, tele...  \n",
      "14  Telecalling, Client Interaction, Marketing, Re...  \n",
      "15     Big Data, Hadoop, Data Analytics, Data Science  \n",
      "16                                       Data Science  \n",
      "17                     Ites, Data Science, Cloud, Iot  \n",
      "18  Social Media, digital media maketing, seo, smm...  \n",
      "19  Corporate Sales, Software Development, Softwar...  \n",
      "20  Data Analytics, Data Science, Machine Learning...  \n",
      "21  Data Science, Machine Learning, Python, R, Dee...  \n",
      "22  Data Science, Artificial Intelligence, Machine...  \n",
      "23  B.tech, Hr Mba, quality assurance engineering,...  \n",
      "24  Big Data, Data Science, Artificial Intelligenc...  \n",
      "25  Java, Net, Angularjs, Hr, Infrastructure, Mana...  \n",
      "26  Software Architecture, Vp Engineering, Product...  \n",
      "27  mechatronics, robotics, Home Automation, iot, ...  \n",
      "28  Data Science, Hadoop, Rpas, Devops, Python, Aw...  \n",
      "29  Signal Processing, Machine Learning, Neural Ne...  \n",
      "30  Web Technologies, Project Management, Software...  \n",
      "31  Data Analytics, Managed Services, Team Leading...  \n",
      "32  Java, Python, Angularjs, Software Testing, Mac...  \n",
      "33  Data Science, Machine Learning, Big Data Analy...  \n",
      "34  Machine Learning, Artificial Intelligence, Dat...  \n",
      "35  C, C++, Artificial Intelligence, Python, Php, ...  \n",
      "36  Relationship Management, Retail Sales, Private...  \n",
      "37                 Data Science, Software Engineering  \n",
      "38  Data Science, Big Data Analytics, Digital Mark...  \n",
      "39                  Data Science, Recruitment, Salary  \n",
      "40  B.Tech, Tableau, Statistics, R, Analytics, Tim...  \n",
      "41  Software Development, Business Intelligence, B...  \n",
      "42                   Data Science, Node.js, Angularjs  \n",
      "43  Data Science, Media Marketing, Resource Planni...  \n",
      "44  Data Analysis, Learning, Data Science, Compute...  \n",
      "45  Java, Hadoop, R, Machine Learning, Spark, Flum...  \n",
      "46  Software Development, Core Java, Unit Testing,...  \n",
      "47  Machine Learning, Data Science, Product Manage...  \n",
      "48  consulting, Education Counseling, Educational ...  \n",
      "49  Software Professionals, Engineering, Technical...  \n"
     ]
    }
   ],
   "source": [
    "#creating dataframe\n",
    "df=pd.DataFrame({'Name':name,\n",
    "                'Designation':designation,\n",
    "                'Company':company,\n",
    "                \"Location\":location,\n",
    "                'Skills I hire':skill})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Top 30 highest selling novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "book_name=[]\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[2]\")\n",
    "    for i in names:\n",
    "        book_name.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    book_name.append('No details available')\n",
    "print(len(book_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "author_name=[]\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[3]\")\n",
    "    for i in names:\n",
    "        author_name.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    author_name.append('No details available')\n",
    "\n",
    "print(len(author_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "author_name=[]\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[4]\")\n",
    "    for i in names:\n",
    "        author_name.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    author_name.append('No details available')\n",
    "\n",
    "print(len(author_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "publisher=[]\n",
    "try:\n",
    "    publishers=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[5]\")\n",
    "    for i in publishers:\n",
    "        publisher.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    publisher.append('No details available')\n",
    "\n",
    "print(len(publisher))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "genre=[]\n",
    "try:\n",
    "    genres=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[6]\")\n",
    "    for i in genres:\n",
    "        genre.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    genre.append('No details available')\n",
    "\n",
    "print(len(genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Book_name Author_name Volume sold  \\\n",
      "0                                   Da Vinci Code,The   5,094,805   5,094,805   \n",
      "1                Harry Potter and the Deathly Hallows   4,475,152   4,475,152   \n",
      "2            Harry Potter and the Philosopher's Stone   4,200,654   4,200,654   \n",
      "3           Harry Potter and the Order of the Phoenix   4,179,479   4,179,479   \n",
      "4                                Fifty Shades of Grey   3,758,936   3,758,936   \n",
      "..                                                ...         ...         ...   \n",
      "95                                          Ghost,The     807,311     807,311   \n",
      "96                     Happy Days with the Naked Chef     794,201     794,201   \n",
      "97              Hunger Games,The:Hunger Games Trilogy     792,187     792,187   \n",
      "98  Lost Boy,The:A Foster Child's Search for the L...     791,507     791,507   \n",
      "99  Jamie's Ministry of Food:Anyone Can Learn to C...     791,095     791,095   \n",
      "\n",
      "          Publisher                        Genre  \n",
      "0        Transworld  Crime, Thriller & Adventure  \n",
      "1        Bloomsbury           Children's Fiction  \n",
      "2        Bloomsbury           Children's Fiction  \n",
      "3        Bloomsbury           Children's Fiction  \n",
      "4      Random House              Romance & Sagas  \n",
      "..              ...                          ...  \n",
      "95     Random House   General & Literary Fiction  \n",
      "96          Penguin        Food & Drink: General  \n",
      "97  Scholastic Ltd.          Young Adult Fiction  \n",
      "98            Orion           Biography: General  \n",
      "99          Penguin        Food & Drink: General  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating dataframe\n",
    "df=pd.DataFrame({\"Book_name\":book_name,\n",
    "                \"Author_name\":author_name,\n",
    "                'Volume sold':Sale,\n",
    "                'Publisher':publisher,\n",
    "                'Genre':genre})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. 100 most watched tv shows of all time from imdb.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.imdb.com/list/ls095964455/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "name=[]\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\")\n",
    "    for i in names:\n",
    "        name.append(i.text)\n",
    "except NosuchElementException:#handling no such element exception\n",
    "    name.append('No details available')\n",
    "print(len(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "years=[]\n",
    "try:\n",
    "    span=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/span[2]\")\n",
    "    for i in span:\n",
    "        years.append(i.text)\n",
    "except NosuchElementException:#handling no such element exception\n",
    "    years.append('No details available')\n",
    "print(len(years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "genre=[]\n",
    "try:\n",
    "    genres=driver.find_elements_by_xpath(\"//span[@class='genre']\")\n",
    "    for i in genres:\n",
    "        genre.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    genre.append('No details available')\n",
    "print(len(genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "run_time=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//span[@class='runtime']\")\n",
    "    for i in info:\n",
    "        run_time.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    run_time.append('No details available')\n",
    "print(len(run_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "rating=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//div[@class='ipl-rating-star small']/span[2]\")\n",
    "    for i in info:\n",
    "        rating.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    rating.append('No details available')\n",
    "print(len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "votes=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//span[@name='nv']\")\n",
    "    for i in info:\n",
    "        votes.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    votes.append('No details available')\n",
    "print(len(votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Name        years                     Genre  \\\n",
      "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
      "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
      "2                 The Walking Dead     (2010– )   Drama, Horror, Thriller   \n",
      "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
      "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
      "..                             ...          ...                       ...   \n",
      "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
      "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
      "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
      "98           Scream: The TV Series     (2015– )      Crime, Drama, Horror   \n",
      "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
      "\n",
      "   Run_time Rating      Votes  \n",
      "0    57 min    9.3  1,730,633  \n",
      "1    51 min    8.8    790,551  \n",
      "2    44 min    8.2    840,371  \n",
      "3    60 min    7.6    251,430  \n",
      "4    43 min    7.6    210,084  \n",
      "..      ...    ...        ...  \n",
      "95   42 min    7.5     42,786  \n",
      "96   50 min    7.8     52,893  \n",
      "97   42 min    8.1    156,684  \n",
      "98   45 min    7.2     33,559  \n",
      "99  572 min    8.6    174,313  \n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating dataframe\n",
    "df=pd.DataFrame({\"Name\":name,\n",
    "                \"years\":years,\n",
    "                \"Genre\":genre,\n",
    "                \"Run_time\":run_time,\n",
    "                \"Rating\":rating,\n",
    "                \"Votes\":votes})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Details of Datasets from UCI machine learning repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://archive.ics.uci.edu/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking show all datasets link\n",
    "show=driver.find_element_by_xpath(\"//a[@href='datasets.php']\")\n",
    "show.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\n"
     ]
    }
   ],
   "source": [
    "#scraping dataset names\n",
    "name=[]\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[1]/table/tbody/tr/td[2]/p/b/a\")\n",
    "    for i in names:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    name.append('No details available')\n",
    "print(len(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\n"
     ]
    }
   ],
   "source": [
    "#scraping dataset names\n",
    "data_type=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]\")\n",
    "    for i in info[1:]:\n",
    "         data_type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    data_type.append(\"No information\")\n",
    "print(len(data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\n"
     ]
    }
   ],
   "source": [
    "#scraping dataset names\n",
    "default_task=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]\")\n",
    "    for i in info[1:]:\n",
    "         default_task.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    default_task.append(\"No information\")\n",
    "print(len(default_task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\n"
     ]
    }
   ],
   "source": [
    "#scraping dataset names\n",
    "attr_type=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]\")\n",
    "    for i in info[1:]:\n",
    "         attr_type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    attr_type.append(\"No information\")\n",
    "print(len(attr_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\n"
     ]
    }
   ],
   "source": [
    "#scraping dataset names\n",
    "no_of_instances=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]\")\n",
    "    for i in info[1:]:\n",
    "         no_of_instances.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    no_of_instances.append(\"No information\")\n",
    "print(len(no_of_instances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\n"
     ]
    }
   ],
   "source": [
    "#scraping dataset names\n",
    "no_of_attributes=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]\")\n",
    "    for i in info[1:]:\n",
    "         no_of_attributes.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    no_of_attributes.append(\"No information\")\n",
    "print(len(no_of_attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\n"
     ]
    }
   ],
   "source": [
    "#scraping dataset names\n",
    "year=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]\")\n",
    "    for i in info[1:]:\n",
    "         year.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    year.append(\"No information\")\n",
    "print(len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Name      Data_type  \\\n",
      "0                                              Abalone  Multivariate    \n",
      "1                                                Adult  Multivariate    \n",
      "2                                            Annealing  Multivariate    \n",
      "3                         Anonymous Microsoft Web Data                  \n",
      "4                                           Arrhythmia  Multivariate    \n",
      "..                                                 ...            ...   \n",
      "554          IIWA14-R820-Gazebo-Dataset-10Trajectories                  \n",
      "555                     Guitar Chords finger positions          Text    \n",
      "556               Russian Corpus of Biographical Texts          Text    \n",
      "557                                        Codon usage  Multivariate    \n",
      "558  Intelligent Media Accelerometer and Gyroscope ...   Time-Series    \n",
      "\n",
      "                            Task               Attribute_type No_of_instances  \\\n",
      "0                Classification   Categorical, Integer, Real            4177    \n",
      "1                Classification         Categorical, Integer           48842    \n",
      "2                Classification   Categorical, Integer, Real             798    \n",
      "3           Recommender-Systems                  Categorical           37711    \n",
      "4                Classification   Categorical, Integer, Real             452    \n",
      "..                           ...                          ...             ...   \n",
      "554                  Regression                      Integer                    \n",
      "555              Classification                                         2633    \n",
      "556              Classification                                          200    \n",
      "557  Classification, Clustering                                        13028    \n",
      "558              Classification                         Real             800    \n",
      "\n",
      "    No_of_attributes   Year  \n",
      "0                 8   1995   \n",
      "1                14   1996   \n",
      "2                38          \n",
      "3               294   1998   \n",
      "4               279   1998   \n",
      "..               ...    ...  \n",
      "554                   2020   \n",
      "555               5   2020   \n",
      "556               2   2020   \n",
      "557              69   2020   \n",
      "558               9   2020   \n",
      "\n",
      "[559 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating dataframe\n",
    "df=pd.DataFrame({'Name':name,\n",
    "                'Data_type':data_type,\n",
    "                'Task':default_task,\n",
    "                'Attribute_type':attr_type,\n",
    "                'No_of_instances':no_of_instances,\n",
    "                'No_of_attributes':no_of_attributes,\n",
    "                'Year':year})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
